##  Installation Notes ##

### Node Design ###

- The Datanode service running on the machines manages the HDFS.

- The Namenode service manages all the datanodes and all blocks of the data. It also manages data 
redundency. For example, when a disk fails Namenode is the service responsible for moving the data 
around to other nodes to ensure minimum level of replication.

- The Tasktracker service manages the different tasks that are run on each node.

- The Jobtracker service manages these Tasktrackers. It keeps information about which tasktracker 
is running a job and which of them are not. It also allocates jobs to all the tasktrackers and is 
responsible for breaking up the jobs into tasks and distributing it across the cluster.

- It must also be noted that in many configurations, the Namenode and the Jobtracker are run on 
the same machine. There are a few situations where these two are run separately.

- Most times the machine(s) that is/are running Namenode and Jobtracker services also run the 
Datanode and the Tasktracker service. This is mainly to extract all available computing power.

- Under conditions when the machine(s) that is/are running Namenode and Jobtracker services are not
very powerful then the Datanode and the Tasktracker services are not run on them.

- The decision to have Datanode and Tasktracker on the Namenode and/or Jobtracker is completely 
dependent on the requirements of each environment.

- On each machine (Datanode and Tasktracker) majority of the available processor cores are used for 
Hadoop and usually a minimal number is kept of other system tasks. For example, on a 4 core Intel 
processor, 3 cores are set aside for Hadoop/Map/Reduce, while one core is allocated for system tasks. 
Similarly, on a 16 Core AMD processor, anywhere between 12 - 14 cores can be set aside for Hadoop and 
the rest for system tasks.

### RAID and Redundancy Design ###

- RAID configuration are usually not used for HDFS. That is mainly because Hadoop itself handles 
redundancy.

- But if there is an opportunity to use RAID then it could definitely be used for /boot and /partition. 
This is mainly to ensure that when one of the hard drives go down the RAID configured partition on the 
other hard drive can seamlessly take over.

- The minimum required redundancy configuration for data on Hadoop is 3. This means that each data block 
is copied at 2 other locations other than its primary location. Hadoop has shown that with 3 copies of 
each data block high availability is possible.